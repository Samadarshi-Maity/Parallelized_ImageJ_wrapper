{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a0a71e",
   "metadata": {},
   "source": [
    "# Image Identification using \"pyimagej\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca680db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FIJI_Marco_For_Particle_Identification import process_NF_particles as pnp\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import time \n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055e83a",
   "metadata": {},
   "source": [
    "## Section under development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35673168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time taken by D:/binary_flock_density_manipulation/density_0.52_date_28.02.2022/13h45_2x2x_5exp_150V_200fps_files/Images/  is  1 minutes\n"
     ]
    }
   ],
   "source": [
    "# parallelization code set\n",
    "# ~~~~~~~~~~~~~~~~~~\"Create  the file architecture \n",
    "# add the main path \n",
    "\n",
    "mainPath  = 'D:/binary_flock_density_manipulation/density_0.52_date_28.02.2022'; \n",
    "# add the last slash as well\n",
    "experimentPath = glob.glob( os.path.normpath(mainPath)+'\\*_files');\n",
    "\n",
    "# add the Images \n",
    "experimentPath = [s + '\\\\Images\\\\' for s in experimentPath];\n",
    "experimentPath = [s .replace('\\\\','/') for s in experimentPath];\n",
    "\n",
    "results = [];\n",
    "\n",
    "for Path in experimentPath[0:1]:\n",
    "\n",
    "    # ~~~~~~~~~~~ Count the total number of frames within the \"Image\" folder ~~~~~~~~~~~~~\n",
    "    Total_Frames = len(glob.glob(Path +'*.tif'));\n",
    "    if (os.path.normpath(glob.glob(Path +'*.tif')[-1]).split(os.sep)[-1] == 'ImageBackground.tif'):\n",
    "        Total_Frames -= 1;\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # ~~~~~~~~~~~~ read the total number of images ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    N  = 18; # specify the number of workers ... do this judiciously  \n",
    "    Ram_size = 18;\n",
    "    memory_allocation = \"-Xmx\" + str(int(Ram_size/N)) + \"g\"; # N*memory alloc. not exceed the RAM size-1\n",
    "    pool = mp.Pool(processes=N);\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~create the chunk firsts and lasts (tested robust) ~~~~~~~~~~~~~~~~~~~\n",
    "    Chunk = (Total_Frames/N);\n",
    "    frame_start = [];\n",
    "    frame_finish =[];\n",
    "    inp_for_starmap =[];\n",
    "\n",
    "    for i in range(N):\n",
    "        frame_start.append(int(np.floor(i*Chunk)+1));\n",
    "        frame_finish.append(int(np.floor((i+1)*Chunk+1)));\n",
    "        inp_for_starmap.append(tuple([Path,frame_start[i],frame_finish[i],memory_allocation]));\n",
    "\n",
    "    #~~~~~~~~~~~~~create a \"main\" function for running the parallization code~~~~~~~~~~~~~\n",
    "    #~~~~ the __main__ function is not necessary on mac and linux .. window 's crap!~~~~~~\n",
    "\n",
    "    if __name__==\"__main__\":\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~ create a temporary folder in C: Drive ~~~~~~~~~~~~~~~~~~~~~~\n",
    "        os.mkdir('C:/Temporary')\n",
    "\n",
    "        start = time.perf_counter();    \n",
    "        # creating N processes and executing them return the location of the file where the array is stored\n",
    "        results = pool.starmap(pnp, inp_for_starmap);\n",
    "\n",
    "        # measure the run time\n",
    "        finish = time.perf_counter();\n",
    "\n",
    "        # closing the pool is very important!! creates problem with multiple running \n",
    "        pool.close();\n",
    "        \n",
    "        # concate the arrays into a single master array\n",
    "        master = np.memmap('C:/Temporary/master.array', dtype='float32', mode='w+', shape = (1,4));\n",
    "        \n",
    "        for i in results:\n",
    "            # thread  a chunk ...\n",
    "            chunk_data = np.memmap(i[0], dtype='float32', mode='r', shape = (i[1],4));\n",
    "            \n",
    "            # measuer the sizes of the mster and the chunk.\n",
    "            master_len = np.shape(master)[0];\n",
    "            chunk_len = np.shape(chunk_data)[0];\n",
    "            \n",
    "            # allocate more size to master\n",
    "            master = np.memmap('C:/Temporary/master.array', dtype='float32', mode='r+', shape = ((master_len + chunk_len-1),4));\n",
    "            \n",
    "            # copy the chunk into master\n",
    "            master[master_len:,:] = np.array(chunk_data[1:,:]);\n",
    "        \n",
    "        \n",
    "        # remove the first line of the master\n",
    "        master = master[1:,:];\n",
    "        \n",
    "        # Transform the path name to the position for saving the .mat output\n",
    "        parts = os.path.normpath(Path).split(os.sep)[:-1];\n",
    "        parts.extend(['Analysis','1_Positions','Positions_NF.mat']);\n",
    "        mat_file_name = '/'.join(parts);\n",
    "        \n",
    "        # Save the data in a .mat file \n",
    "        dictn = {\"XYF\":master};\n",
    "        sio.savemat(mat_file_name, dictn); \n",
    "        \n",
    "        # remove the large datasets from the memory and collect garbage \n",
    "        del(results);\n",
    "        del(master);\n",
    "        del(dictn);\n",
    "        del(chunk_data)\n",
    "        gc.collect();\n",
    "        print(\" time taken by\",Path,\" is \", round((finish - start)/60),\"minutes\");\n",
    "        \n",
    "        # delete the temprorary folder in C: drive\n",
    "        shutil.rmtree('C:/Temporary');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c6e8b",
   "metadata": {},
   "source": [
    "# Legacy sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d09fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallelization code set\n",
    "# ~~~~~~~~~~~~~~~~~~\"Create  the file architecture \n",
    "# add the main path \n",
    "\n",
    "mainPath  = 'D:/binary_flock_density_manipulation/density_1.00_date_11.3.2022'; \n",
    "# add the last slash as well\n",
    "experimentPath = glob.glob( os.path.normpath(mainPath)+'\\*_files');\n",
    "\n",
    "# add the Images \n",
    "experimentPath = [s + '\\\\Images\\\\' for s in experimentPath];\n",
    "experimentPath = [s .replace('\\\\','/') for s in experimentPath];\n",
    "\n",
    "results = [];\n",
    "\n",
    "for Path in experimentPath:\n",
    "\n",
    "    # ~~~~~~~~~~~ Count the total number of frames within the \"Image\" folder ~~~~~~~~~~~~~\n",
    "    Total_Frames = len(glob.glob(Path +'*.tif'));\n",
    "    if (os.path.normpath(glob.glob(Path +'*.tif')[-1]).split(os.sep)[-1] == 'ImageBackground.tif'):\n",
    "        Total_Frames -= 1;\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # ~~~~~~~~~~~~ read the total number of images ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    N  = 8; # specify the number of workers ... do this judiciously  \n",
    "    Ram_size = 24;\n",
    "    memory_allocation = \"-Xmx\" + str(int (Ram_size/N)) + \"g\"; # N*memory alloc. not exceed the RAM size-1\n",
    "    pool = mp.Pool(processes=N);\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~create the chunk firsts and lasts (tested robust) ~~~~~~~~~~~~~~~~~~~\n",
    "    Chunk = (Total_Frames/N);\n",
    "    frame_start = [];\n",
    "    frame_finish =[];\n",
    "    inp_for_starmap =[];\n",
    "\n",
    "    for i in range(N):\n",
    "        frame_start.append(int(np.floor(i*Chunk)+1));\n",
    "        frame_finish.append(int(np.floor((i+1)*Chunk+1)));\n",
    "        inp_for_starmap.append(tuple([Path,frame_start[i],frame_finish[i],memory_allocation]));\n",
    "\n",
    "    #~~~~~~~~~~~~~create a \"main\" function for running the parallization code~~~~~~~~~~~~~\n",
    "    #~~~~ the __main__ function is not necessary on mac and linux .. window 's crap!~~~~~~\n",
    "\n",
    "    if __name__==\"__main__\":\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~ create a temporary folder in C: Drive ~~~~~~~~~~~~~~~~~~~~~~\n",
    "        os.mkdir('C:/Temporary')\n",
    "\n",
    "        start = time.perf_counter();    \n",
    "        # creating N processes and executing them\n",
    "        results = pool.starmap(pnp, inp_for_starmap);\n",
    "        \n",
    "        # convert every float64 to float32\n",
    "        for c in range(N):\n",
    "            results[c][results[c].select_dtypes(np.float64).columns] = results[c].select_dtypes(np.float64).astype(np.float32);\n",
    "\n",
    "        # measure the run time\n",
    "        finish = time.perf_counter();\n",
    "\n",
    "        # delete the temprorary folder in C: drive\n",
    "        shutil.rmtree('C:/Temporary');\n",
    "        \n",
    "        # closing the pool is very important!! creates problem with multiple running \n",
    "        pool.close()\n",
    "\n",
    "        # Transform the path name to the position for saving the .mat output\n",
    "        parts = os.path.normpath(Path).split(os.sep)[:-1];\n",
    "        parts.extend(['Analysis','1_Positions','Positions_NF.mat']);\n",
    "        mat_file_name = '/'.join(parts);\n",
    "\n",
    "        # Save the data in a .mat file \n",
    "        dictn = {\"XYF\":np.concatenate(results)};\n",
    "        sio.savemat(mat_file_name, dictn); \n",
    "        \n",
    "        # remove the large datasets from the memory and collect garbage \n",
    "        del(results);\n",
    "        del(dictn);\n",
    "        gc.collect(generation = 2);\n",
    "        gc.collect(generation = 1);\n",
    "        gc.collect(generation = 0);\n",
    "        gc.collect();\n",
    "        print(\" time taken by\",Path,\" is \", round((finish - start)/60),\"minutes\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
